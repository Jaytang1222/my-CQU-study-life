import os
import shutil
import random

# --- é…ç½®å‚æ•° ---

# åŒ…å«æ‰€æœ‰åŸå§‹å›¾åƒçš„æ ¹ç›®å½•ï¼ˆä¾‹å¦‚ï¼šCroppedImagesï¼‰
SOURCE_ROOT = r'C:\Users\jayta\Desktop\study\qhx\finalhomework\CroppedImages'

# ç›®æ ‡æ•°æ®é›†çš„æ ¹ç›®å½•ï¼Œè„šæœ¬å°†åœ¨è¿™é‡Œåˆ›å»º train å’Œ val æ–‡ä»¶å¤¹
DESTINATION_ROOT = r'C:\Users\jayta\Desktop\study\qhx\finalhomework\dataset'

# è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„åˆ’åˆ†æ¯”ä¾‹ (ä¾‹å¦‚: 0.8 ä»£è¡¨ 80% è®­ç»ƒé›†, 20% éªŒè¯é›†)
TRAIN_SPLIT_RATIO = 0.8


# --- ä¸»è¦å‡½æ•° ---

def organize_dataset(source_dir, dest_dir, split_ratio):
    """
    éå†æºç›®å½•ä¸­çš„å›¾ç‰‡ï¼Œæ ¹æ®æ–‡ä»¶ååç¼€è¿›è¡Œåˆ†ç±»ï¼ˆclean/noisyï¼‰ï¼Œ
    å¹¶æŒ‰æ¯”ä¾‹åˆ’åˆ†åˆ°ç›®æ ‡ç›®å½•çš„ train/val å­ç›®å½•ä¸­ã€‚
    """
    print(f"ğŸš€ å¼€å§‹å¤„ç†ç›®å½•: {source_dir}")

    # 1. å®šä¹‰ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    train_clean_dir = os.path.join(dest_dir, 'train', 'clean')
    train_noisy_dir = os.path.join(dest_dir, 'train', 'noisy')
    val_clean_dir = os.path.join(dest_dir, 'val', 'clean')
    val_noisy_dir = os.path.join(dest_dir, 'val', 'noisy')

    # ç¡®ä¿æ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(train_clean_dir, exist_ok=True)
    os.makedirs(train_noisy_dir, exist_ok=True)
    os.makedirs(val_clean_dir, exist_ok=True)
    os.makedirs(val_noisy_dir, exist_ok=True)

    # 2. æ”¶é›†æ–‡ä»¶å¯¹
    # ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨ (æ–‡ä»¶åå…¬å…±éƒ¨åˆ†: æ–‡ä»¶è·¯å¾„) çš„æ˜ å°„
    # ä¾‹å¦‚: 'Canon5D2_5_160_3200_chair_5': ['..._mean.JPG', '..._real.JPG']
    file_pairs = {}

    # éå†æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(source_dir):
        if filename.endswith(('_mean.JPG', '_real.JPG')):
            full_path = os.path.join(source_dir, filename)

            # æå–æ–‡ä»¶åå…¬å…±éƒ¨åˆ†ï¼ˆä¸åŒ…å« _mean.JPG æˆ– _real.JPGï¼‰
            # ä¾‹å¦‚ 'Canon5D2_5_160_3200_chair_5_mean.JPG' -> 'Canon5D2_5_160_3200_chair_5'
            base_name = filename.rsplit('_', 1)[0]

            if base_name not in file_pairs:
                file_pairs[base_name] = []

            file_pairs[base_name].append(full_path)

    # 3. ç­›é€‰å‡ºæœ‰æ•ˆçš„ clean/noisy å›¾åƒå¯¹
    valid_pairs = []
    for base_name, paths in file_pairs.items():
        # å¿…é¡»åŒæ—¶å­˜åœ¨ mean (clean) å’Œ real (noisy) æ–‡ä»¶æ‰èƒ½æ„æˆæœ‰æ•ˆå¯¹
        mean_path = next((p for p in paths if p.endswith('_mean.JPG')), None)
        real_path = next((p for p in paths if p.endswith('_real.JPG')), None)

        if mean_path and real_path:
            valid_pairs.append({'base_name': base_name, 'clean': mean_path, 'noisy': real_path})

    print(f"âœ… æ‰¾åˆ° {len(valid_pairs)} å¯¹æœ‰æ•ˆçš„ clean/noisy å›¾åƒã€‚")
    if not valid_pairs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒå¯¹ã€‚è¯·æ£€æŸ¥ SOURCE_ROOT å’Œæ–‡ä»¶å‘½åæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        return

    # 4. éšæœºåˆ’åˆ†æ•°æ®é›†
    random.shuffle(valid_pairs)
    split_index = int(len(valid_pairs) * split_ratio)

    train_pairs = valid_pairs[:split_index]
    val_pairs = valid_pairs[split_index:]

    print(f"ğŸ“Š åˆ’åˆ†ç»“æœ: è®­ç»ƒé›† {len(train_pairs)} å¯¹, éªŒè¯é›† {len(val_pairs)} å¯¹ã€‚")

    # 5. å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
    def copy_files(pairs, clean_dest, noisy_dest):
        """å°†å›¾åƒå¯¹å¤åˆ¶åˆ°æŒ‡å®šçš„ clean å’Œ noisy ç›®æ ‡ç›®å½•"""
        count = 0
        for pair in pairs:
            base_name = pair['base_name']
            clean_src = pair['clean']
            noisy_src = pair['noisy']

            # ä½¿ç”¨åŸå§‹æ–‡ä»¶åä½œä¸ºç›®æ ‡æ–‡ä»¶å
            clean_dest_path = os.path.join(clean_dest, os.path.basename(clean_src))
            noisy_dest_path = os.path.join(noisy_dest, os.path.basename(noisy_src))

            try:
                # å¤åˆ¶ clean å›¾åƒ
                shutil.copy2(clean_src, clean_dest_path)
                # å¤åˆ¶ noisy å›¾åƒ
                shutil.copy2(noisy_src, noisy_dest_path)
                count += 1
            except Exception as e:
                print(f"âš ï¸ å¤åˆ¶æ–‡ä»¶æ—¶å‡ºé”™ {base_name}: {e}")
        return count

    print("\nğŸ“¦ æ­£åœ¨å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶...")
    train_count = copy_files(train_pairs, train_clean_dir, train_noisy_dir)

    print("ğŸ“¦ æ­£åœ¨å¤åˆ¶éªŒè¯é›†æ–‡ä»¶...")
    val_count = copy_files(val_pairs, val_clean_dir, val_noisy_dir)

    print("\nğŸ‰ æ•°æ®é›†æ•´ç†å®Œæˆ!")
    print(f"   - è®­ç»ƒé›†å›¾åƒæ•°: {train_count * 2} (clean: {train_count}, noisy: {train_count})")
    print(f"   - éªŒè¯é›†å›¾åƒæ•°: {val_count * 2} (clean: {val_count}, noisy: {val_count})")
    print(f"   - ç›®æ ‡ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š")

    # æ‰“å°æœ€ç»ˆç›®å½•ç»“æ„
    print(f"     {DESTINATION_ROOT}")
    print(f"     â”œâ”€â”€ train")
    print(f"     â”‚   â”œâ”€â”€ clean (å…± {train_count} å¼  GT å›¾)")
    print(f"     â”‚   â””â”€â”€ noisy (å…± {train_count} å¼ å¸¦å™ªå›¾)")
    print(f"     â””â”€â”€ val")
    print(f"         â”œâ”€â”€ clean (å…± {val_count} å¼  GT å›¾)")
    print(f"         â””â”€â”€ noisy (å…± {val_count} å¼ å¸¦å™ªå›¾)")


if __name__ == '__main__':
    organize_dataset(SOURCE_ROOT, DESTINATION_ROOT, TRAIN_SPLIT_RATIO)